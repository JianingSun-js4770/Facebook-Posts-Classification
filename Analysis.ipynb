{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will be using three more features apart from text feature i.e. like, share and owner type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features1 = ['owner_type']\n",
    "features2 = ['nb_like', 'nb_share']\n",
    "features3 = ['nb_like', 'nb_share', 'owner_type']\n",
    "categ_dict = {'OK': 0, 'Reseller': 1, 'Non': 2}\n",
    "owner_dict = {'user': 0, 'page': 1}\n",
    "\n",
    "def string_to_int(row, some_dict):\n",
    "    if row in some_dict:\n",
    "        row = some_dict[row]\n",
    "    return row\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words={'english'})\n",
    "\n",
    "def vectorize_text_tfidf(dataframe, type_dataframe):\n",
    "    if type_dataframe == \"train\":\n",
    "        return vectorizer.fit_transform(dataframe['text'].values)\n",
    "    elif type_dataframe == \"test\":\n",
    "        return vectorizer.transform(dataframe['text'].values)\n",
    "    else:\n",
    "        return \"Please enter train or test\"\n",
    "    \n",
    "def concat_features(dataframe, tfidf_text_features, features_list):\n",
    "    for x in features_list:\n",
    "        features = hstack((tfidf_text_features, dataframe[x].values.reshape(tfidf_text_features.shape[0], 1)))\n",
    "    return features\n",
    "\n",
    "# TODO - stemming\n",
    "def text_preprocessing(text):\n",
    "    # for removing html tags from text\n",
    "    text = BeautifulSoup(text, 'html5lib')\n",
    "    # to keep only english letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text.get_text())\n",
    "    # to remove spaces, tabs and new lines\n",
    "    text = re.sub( '\\s+', ' ', text).strip().lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the data and data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"Facebook_Sellers_Challenge.csv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Converting target label and other features to numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert target labels to numeric\n",
    "data_df['INDEX New'] = data_df['INDEX New'].apply(string_to_int, args=(categ_dict,))\n",
    "data_df['owner_type'] = data_df['owner_type'].apply(string_to_int, args=(owner_dict,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classifying data with minimal cleaning using all features\n",
    "#### Let's test out data with raw data in tfidf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop rows where description is Nan \n",
    "raw_data_df = data_df.dropna(subset=[\"description\", \"owner_type\"])\n",
    "# rename columns for more readable columns name\n",
    "raw_data_df = raw_data_df.rename(columns = {'description':'text', 'INDEX New': 'label'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data points in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "label       \n",
       "0       8187\n",
       "1       7548\n",
       "2      11880"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_df.groupby(['label']).agg(['count'])['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_df, raw_test_df = train_test_split(raw_data_df, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_tfidf = concat_features(raw_train_df, vectorize_text_tfidf(raw_train_df, \"train\"), features3)\n",
    "# these parameters were learned from grid search below\n",
    "raw_forest = RandomForestClassifier(n_estimators = 200, oob_score=True, n_jobs=-1, max_features=\"auto\")\n",
    "raw_forest = raw_forest.fit(raw_train_tfidf, raw_train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 86.06\n"
     ]
    }
   ],
   "source": [
    "raw_test_tfidf = concat_features(raw_test_df, vectorizer.transform(raw_test_df['text'].values), features3)\n",
    "\n",
    "predicted = raw_forest.predict(raw_test_tfidf)\n",
    "print(\"Accuracy : %0.2f\" % (np.mean(predicted == raw_test_df['label'].values) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get around 86% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But this is not very good approach as we need to do cleaning and get just words for good features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop rows where description is Nan \n",
    "data_df = data_df.dropna(subset=[\"description\", \"owner_type\"])\n",
    "# drop duplicates based on multiple features\n",
    "data_df = data_df.drop_duplicates(subset=[\"description\", \"nb_like\", \"nb_share\", \"owner_type\"]).reset_index()\n",
    "# rename columns for more readable columns name\n",
    "data_df = data_df.rename(columns = {'description':'text', 'INDEX New': 'label'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Cleaning text for good and clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I lost around 12,000 data points in this whole process but I felt it is important because there were lot or rows with no description, duplicates and also empty description after this text processing step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df['text'] = data_df['text'].apply(text_preprocessing)\n",
    "data_df = data_df.drop(data_df[data_df.text == \"\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data distribution for three categories.\n",
    "#### 0 - 'OK', 1 - 'Reseller', 2 - 'Non'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "label       \n",
       "0       6192\n",
       "1       5988\n",
       "2      10182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby(['label']).agg(['count'])['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.1 Random Forest\n",
    "### 2.1.1 Grid Search of Random forest Algorithm to find the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all data into Tf-Idf vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert text into tfidf vector form\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words={'english'})\n",
    "text_data_tfidf = vectorizer.fit_transform(data_df['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Initilization with initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize model with parameters\n",
    "rfc = RandomForestClassifier(n_jobs=-1, max_features='sqrt', n_estimators=50, oob_score=True)\n",
    "# parameters to optimize\n",
    "# I think these two parameters (n_estimators, and max_features) are very important to optimize.\n",
    "params = { \n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the grid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the GridSearchCV object with parameters\n",
    "# run a cross validation for 5 sets of data\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=params, cv= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=-1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 200, 500, 100], 'max_features': ['auto', 'sqrt', 'log2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data to find the optimal parameters\n",
    "CV_rfc.fit(text_data_tfidf, data_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'n_estimators': 200}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params_ attribute gives the best parameters to be used for the model for our data.\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Classification using learned parameters of Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the pipeline for our classifcation task to make it more readable\n",
    "# n_jobs = -1 will use all the processors. You can limit it to one by setting n_jobs = 1\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer',   CountVectorizer(stop_words={'english'})),\n",
    "    ('tfidf_transformer',  TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators = 200, max_features=\"auto\", n_jobs=-1, oob_score=True))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting our pipeline with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words={'engli...mators=200, n_jobs=-1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train_df['text'].values, train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our dataset with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 83.21\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(test_df['text'].values)\n",
    "mean_accuracy = np.mean(predictions == test_df['label'].values) * 100\n",
    "print(\"Mean accuracy: %.2f\" % mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different metrics of our classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         OK       0.82      0.85      0.83      1262\n",
      "   Reseller       0.84      0.72      0.77      1183\n",
      "        Non       0.83      0.89      0.86      2028\n",
      "\n",
      "avg / total       0.83      0.83      0.83      4473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['OK', 'Reseller', 'Non']\n",
    "print(classification_report(test_df['label'].values, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrices\n",
    "#### 0 - 'OK', 1 - 'Reseller', 2 - 'Non'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1069</td>\n",
       "      <td>76</td>\n",
       "      <td>117</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>846</td>\n",
       "      <td>248</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>80</td>\n",
       "      <td>1807</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1299</td>\n",
       "      <td>1002</td>\n",
       "      <td>2172</td>\n",
       "      <td>4473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1     2   All\n",
       "True                             \n",
       "0          1069    76   117  1262\n",
       "1            89   846   248  1183\n",
       "2           141    80  1807  2028\n",
       "All        1299  1002  2172  4473"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix with number of false and true classifcations\n",
    "pd.crosstab(test_df['label'].values, predictions, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Non</th>\n",
       "      <th>OK</th>\n",
       "      <th>Reseller</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non</th>\n",
       "      <td>83.195212</td>\n",
       "      <td>10.854503</td>\n",
       "      <td>7.984032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>5.386740</td>\n",
       "      <td>82.294072</td>\n",
       "      <td>7.584830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reseller</th>\n",
       "      <td>11.418048</td>\n",
       "      <td>6.851424</td>\n",
       "      <td>84.431138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted        Non         OK   Reseller\n",
       "True                                      \n",
       "Non        83.195212  10.854503   7.984032\n",
       "OK          5.386740  82.294072   7.584830\n",
       "Reseller   11.418048   6.851424  84.431138"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = {0 : 'OK', 1: 'Reseller', 2: 'Non'}\n",
    "y_true = pd.Series([lookup[_] for _ in test_df['label'].values])\n",
    "y_pred = pd.Series([lookup[_] for _ in predictions])\n",
    "pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted']).apply(lambda r: 100.0 * r/r.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Combining models with VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting tf-idf vector of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train_tfidf = concat_features(train_df, vectorize_text_tfidf(train_df, \"train\"), features3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining three models: Multinomial Naive Bayes, Random Forest and Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = MultinomialNB()\n",
    "model2 = RandomForestClassifier(n_estimators = 200, oob_score=True, n_jobs=-1, max_features=\"auto\")\n",
    "model3 = svm.SVC(kernel='rbf', probability=True)\n",
    "ensemble = VotingClassifier(estimators=[('np', model1), ('forest', model2), \n",
    "                                        ('svc', model3)], voting='soft', weights=[2,3,1], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble = ensemble.fit(text_train_tfidf,train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 83.28 \n"
     ]
    }
   ],
   "source": [
    "text_test_tfidf = concat_features(test_df, vectorizer.transform(test_df['text'].values), features3)\n",
    "\n",
    "predicted = ensemble.predict(text_test_tfidf)\n",
    "print(\"Accuracy : %0.2f \" % (np.mean(predicted == test_df['label'].values) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models with Multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "#### Using all features becasue not much difference with using less or more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train_tfidf = concat_features(train_df, vectorize_text_tfidf(train_df, \"train\"), features3)\n",
    "\n",
    "forest2 = RandomForestClassifier(n_estimators = 200, oob_score=True, n_jobs=-1, max_features=\"auto\")\n",
    "forest2 = forest2.fit(text_train_tfidf, train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 83.52 \n"
     ]
    }
   ],
   "source": [
    "text_test_tfidf = concat_features(test_df, vectorizer.transform(test_df['text'].values), features3)\n",
    "\n",
    "predicted = forest2.predict(text_test_tfidf)\n",
    "print(\"Accuracy : %0.2f \" % (np.mean(predicted == test_df['label'].values) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "#### Here the best results came up with using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train_tfidf = concat_features(train_df, vectorize_text_tfidf(train_df, \"train\"), features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb = mnb.fit(text_train_tfidf, train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 79.83\n"
     ]
    }
   ],
   "source": [
    "text_test_tfidf = concat_features(test_df, vectorizer.transform(test_df['text'].values), features3)\n",
    "\n",
    "predicted = mnb.predict(text_test_tfidf)\n",
    "print(\"Accuracy : %0.2f\" % (np.mean(predicted == test_df['label'].values) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train_tfidf = concat_features(train_df, vectorize_text_tfidf(train_df, \"train\"), features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model = svm.LinearSVC()\n",
    "svm_model = svm_model.fit(text_train_tfidf, train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 82.36\n"
     ]
    }
   ],
   "source": [
    "text_test_tfidf = concat_features(test_df, vectorizer.transform(test_df['text'].values), features3)\n",
    "\n",
    "predicted = svm_model.predict(text_test_tfidf)\n",
    "print(\"Accuracy : %0.2f\" % (np.mean(predicted == test_df['label'].values) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.4 OneVsRestClassifier and Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train_tfidf = concat_features(train_df, vectorize_text_tfidf(train_df, \"train\"), features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onevsone_model = OneVsRestClassifier(RandomForestClassifier(n_estimators = 200, oob_score=True, \n",
    "                            max_features=\"auto\"), n_jobs=-1).fit(text_train_tfidf, train_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.70\n"
     ]
    }
   ],
   "source": [
    "text_test_tfidf = concat_features(test_df, vectorize_text_tfidf(test_df, \"test\"), features3)\n",
    "\n",
    "predicted = onevsone_model.predict(text_test_tfidf)\n",
    "print(\"Accuracy: %0.2f\" % (np.mean(predicted == test_df['label'].values) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
